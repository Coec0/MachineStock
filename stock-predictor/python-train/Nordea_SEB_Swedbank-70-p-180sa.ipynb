{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_ = pd.read_csv(\"data/x_Nordea_SEB_Swedbank_70_p.csv\", sep=\";\", usecols = [i for i in range(70)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_ = pd.read_csv(\"data/y_Nordea_SEB_Swedbank_70.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nordea_Bank_Abp-price-0</th>\n",
       "      <th>Nordea_Bank_Abp-price-1</th>\n",
       "      <th>Nordea_Bank_Abp-price-2</th>\n",
       "      <th>Nordea_Bank_Abp-price-3</th>\n",
       "      <th>Nordea_Bank_Abp-price-4</th>\n",
       "      <th>Nordea_Bank_Abp-price-5</th>\n",
       "      <th>Nordea_Bank_Abp-price-6</th>\n",
       "      <th>Nordea_Bank_Abp-price-7</th>\n",
       "      <th>Nordea_Bank_Abp-price-8</th>\n",
       "      <th>Nordea_Bank_Abp-price-9</th>\n",
       "      <th>...</th>\n",
       "      <th>Nordea_Bank_Abp-price-60</th>\n",
       "      <th>Nordea_Bank_Abp-price-61</th>\n",
       "      <th>Nordea_Bank_Abp-price-62</th>\n",
       "      <th>Nordea_Bank_Abp-price-63</th>\n",
       "      <th>Nordea_Bank_Abp-price-64</th>\n",
       "      <th>Nordea_Bank_Abp-price-65</th>\n",
       "      <th>Nordea_Bank_Abp-price-66</th>\n",
       "      <th>Nordea_Bank_Abp-price-67</th>\n",
       "      <th>Nordea_Bank_Abp-price-68</th>\n",
       "      <th>Nordea_Bank_Abp-price-69</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>...</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>...</td>\n",
       "      <td>69.80</td>\n",
       "      <td>69.80</td>\n",
       "      <td>69.80</td>\n",
       "      <td>69.70</td>\n",
       "      <td>69.70</td>\n",
       "      <td>69.70</td>\n",
       "      <td>69.76</td>\n",
       "      <td>69.76</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>...</td>\n",
       "      <td>69.80</td>\n",
       "      <td>69.80</td>\n",
       "      <td>69.80</td>\n",
       "      <td>69.70</td>\n",
       "      <td>69.70</td>\n",
       "      <td>69.70</td>\n",
       "      <td>69.76</td>\n",
       "      <td>69.76</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>...</td>\n",
       "      <td>69.80</td>\n",
       "      <td>69.80</td>\n",
       "      <td>69.80</td>\n",
       "      <td>69.70</td>\n",
       "      <td>69.70</td>\n",
       "      <td>69.70</td>\n",
       "      <td>69.76</td>\n",
       "      <td>69.76</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>...</td>\n",
       "      <td>69.80</td>\n",
       "      <td>69.80</td>\n",
       "      <td>69.70</td>\n",
       "      <td>69.70</td>\n",
       "      <td>69.70</td>\n",
       "      <td>69.76</td>\n",
       "      <td>69.76</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nordea_Bank_Abp-price-0  Nordea_Bank_Abp-price-1  Nordea_Bank_Abp-price-2  \\\n",
       "0                    69.88                    69.88                    69.88   \n",
       "1                    69.88                    69.88                    69.88   \n",
       "2                    69.88                    69.88                    69.88   \n",
       "3                    69.88                    69.88                    69.88   \n",
       "4                    69.88                    69.88                    69.88   \n",
       "\n",
       "   Nordea_Bank_Abp-price-3  Nordea_Bank_Abp-price-4  Nordea_Bank_Abp-price-5  \\\n",
       "0                    69.88                    69.88                    69.88   \n",
       "1                    69.88                    69.88                    69.88   \n",
       "2                    69.88                    69.88                    69.88   \n",
       "3                    69.88                    69.88                    69.88   \n",
       "4                    69.88                    69.88                    69.88   \n",
       "\n",
       "   Nordea_Bank_Abp-price-6  Nordea_Bank_Abp-price-7  Nordea_Bank_Abp-price-8  \\\n",
       "0                    69.88                    69.88                    69.88   \n",
       "1                    69.88                    69.88                    69.88   \n",
       "2                    69.88                    69.88                    69.88   \n",
       "3                    69.88                    69.88                    69.88   \n",
       "4                    69.88                    69.88                    69.88   \n",
       "\n",
       "   Nordea_Bank_Abp-price-9  ...  Nordea_Bank_Abp-price-60  \\\n",
       "0                    69.88  ...                     69.88   \n",
       "1                    69.88  ...                     69.80   \n",
       "2                    69.88  ...                     69.80   \n",
       "3                    69.88  ...                     69.80   \n",
       "4                    69.88  ...                     69.80   \n",
       "\n",
       "   Nordea_Bank_Abp-price-61  Nordea_Bank_Abp-price-62  \\\n",
       "0                     69.88                     69.88   \n",
       "1                     69.80                     69.80   \n",
       "2                     69.80                     69.80   \n",
       "3                     69.80                     69.80   \n",
       "4                     69.80                     69.70   \n",
       "\n",
       "   Nordea_Bank_Abp-price-63  Nordea_Bank_Abp-price-64  \\\n",
       "0                     69.88                     69.88   \n",
       "1                     69.70                     69.70   \n",
       "2                     69.70                     69.70   \n",
       "3                     69.70                     69.70   \n",
       "4                     69.70                     69.70   \n",
       "\n",
       "   Nordea_Bank_Abp-price-65  Nordea_Bank_Abp-price-66  \\\n",
       "0                     69.88                     69.88   \n",
       "1                     69.70                     69.76   \n",
       "2                     69.70                     69.76   \n",
       "3                     69.70                     69.76   \n",
       "4                     69.76                     69.76   \n",
       "\n",
       "   Nordea_Bank_Abp-price-67  Nordea_Bank_Abp-price-68  \\\n",
       "0                     69.88                     69.88   \n",
       "1                     69.76                     69.88   \n",
       "2                     69.76                     69.88   \n",
       "3                     69.76                     69.88   \n",
       "4                     69.88                     69.88   \n",
       "\n",
       "   Nordea_Bank_Abp-price-69  \n",
       "0                     69.88  \n",
       "1                     69.88  \n",
       "2                     69.88  \n",
       "3                     69.88  \n",
       "4                     69.75  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>15s</th>\n",
       "      <th>15sa</th>\n",
       "      <th>15ud</th>\n",
       "      <th>30s</th>\n",
       "      <th>30sa</th>\n",
       "      <th>30ud</th>\n",
       "      <th>45s</th>\n",
       "      <th>45sa</th>\n",
       "      <th>45ud</th>\n",
       "      <th>60s</th>\n",
       "      <th>...</th>\n",
       "      <th>180s</th>\n",
       "      <th>180sa</th>\n",
       "      <th>180ud</th>\n",
       "      <th>300s</th>\n",
       "      <th>300sa</th>\n",
       "      <th>300ud</th>\n",
       "      <th>600s</th>\n",
       "      <th>600sa</th>\n",
       "      <th>600ud</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69.71</td>\n",
       "      <td>69.7</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.7</td>\n",
       "      <td>69.635000</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.64</td>\n",
       "      <td>69.69125</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.70</td>\n",
       "      <td>...</td>\n",
       "      <td>69.5</td>\n",
       "      <td>69.475000</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.51</td>\n",
       "      <td>69.529355</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.56</td>\n",
       "      <td>69.570000</td>\n",
       "      <td>-1</td>\n",
       "      <td>1604390403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69.71</td>\n",
       "      <td>69.7</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.7</td>\n",
       "      <td>69.635000</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.64</td>\n",
       "      <td>69.69125</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.65</td>\n",
       "      <td>...</td>\n",
       "      <td>69.5</td>\n",
       "      <td>69.475000</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.51</td>\n",
       "      <td>69.529355</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.56</td>\n",
       "      <td>69.570000</td>\n",
       "      <td>-1</td>\n",
       "      <td>1604390404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.71</td>\n",
       "      <td>69.7</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.7</td>\n",
       "      <td>69.635000</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.64</td>\n",
       "      <td>69.69125</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.65</td>\n",
       "      <td>...</td>\n",
       "      <td>69.5</td>\n",
       "      <td>69.475000</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.51</td>\n",
       "      <td>69.529355</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.56</td>\n",
       "      <td>69.570000</td>\n",
       "      <td>-1</td>\n",
       "      <td>1604390405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.71</td>\n",
       "      <td>69.7</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.7</td>\n",
       "      <td>69.635000</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.64</td>\n",
       "      <td>69.69125</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.65</td>\n",
       "      <td>...</td>\n",
       "      <td>69.5</td>\n",
       "      <td>69.475000</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.51</td>\n",
       "      <td>69.529355</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.56</td>\n",
       "      <td>69.570000</td>\n",
       "      <td>-1</td>\n",
       "      <td>1604390406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69.71</td>\n",
       "      <td>69.7</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.7</td>\n",
       "      <td>69.684286</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.64</td>\n",
       "      <td>69.74000</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.72</td>\n",
       "      <td>...</td>\n",
       "      <td>69.5</td>\n",
       "      <td>69.478571</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.51</td>\n",
       "      <td>69.540930</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.56</td>\n",
       "      <td>69.572273</td>\n",
       "      <td>-1</td>\n",
       "      <td>1604390407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     15s  15sa  15ud   30s       30sa  30ud    45s      45sa  45ud    60s  \\\n",
       "0  69.71  69.7    -1  69.7  69.635000    -1  69.64  69.69125    -1  69.70   \n",
       "1  69.71  69.7    -1  69.7  69.635000    -1  69.64  69.69125    -1  69.65   \n",
       "2  69.71  69.7    -1  69.7  69.635000    -1  69.64  69.69125    -1  69.65   \n",
       "3  69.71  69.7    -1  69.7  69.635000    -1  69.64  69.69125    -1  69.65   \n",
       "4  69.71  69.7    -1  69.7  69.684286    -1  69.64  69.74000    -1  69.72   \n",
       "\n",
       "   ...  180s      180sa  180ud   300s      300sa  300ud   600s      600sa  \\\n",
       "0  ...  69.5  69.475000     -1  69.51  69.529355     -1  69.56  69.570000   \n",
       "1  ...  69.5  69.475000     -1  69.51  69.529355     -1  69.56  69.570000   \n",
       "2  ...  69.5  69.475000     -1  69.51  69.529355     -1  69.56  69.570000   \n",
       "3  ...  69.5  69.475000     -1  69.51  69.529355     -1  69.56  69.570000   \n",
       "4  ...  69.5  69.478571     -1  69.51  69.540930     -1  69.56  69.572273   \n",
       "\n",
       "   600ud          ts  \n",
       "0     -1  1604390403  \n",
       "1     -1  1604390404  \n",
       "2     -1  1604390405  \n",
       "3     -1  1604390406  \n",
       "4     -1  1604390407  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5427519, 70)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = x_data_[:-1]\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5427519,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = y_data_[:-2]\n",
    "y_data = y_data[\"180sa\"] #300s - 5min exakt price\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(xs, ys, trainRatio):\n",
    "    t = round(len(xs)*trainRatio)\n",
    "    \n",
    "    train_data_x = torch.tensor(xs[:t].values, dtype=torch.float32)\n",
    "    train_data_y = torch.tensor(ys[:t].values, dtype=torch.float32)\n",
    "    \n",
    "    d = round(len(xs[t:])/2)\n",
    "    \n",
    "    dev_data_x = torch.tensor(xs[t:][:d].values, dtype=torch.float32)\n",
    "    dev_data_y = torch.tensor(ys[t:][:d].values, dtype=torch.float32)\n",
    "    \n",
    "    test_data_x = torch.tensor(xs[t:][d:].values, dtype=torch.float32)\n",
    "    test_data_y = torch.tensor(ys[t:][d:].values, dtype=torch.float32)\n",
    "    \n",
    "    #print(test_data_y.shape)\n",
    "    \n",
    "    return TensorDataset(train_data_x, train_data_y), TensorDataset(dev_data_x, dev_data_y), list(zip(test_data_x, test_data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, dev_data, test_data = splitData(x_data, y_data, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=70\n",
    "batch_size=512\n",
    "nbr_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute_unit = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device('cuda:0')\n",
    "#compute_unit = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtype = torch.FloatTensor\n",
    "dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 30).type(dtype)\n",
    "        #torch.nn.init.normal_(self.fc1.weight, mean=0, std=1.0)\n",
    "        self.fc2 = nn.Linear(30, 5).type(dtype)\n",
    "        self.fc3 = nn.Linear(5, 30).type(dtype)\n",
    "        self.fc4 = nn.Linear(30, 10).type(dtype)\n",
    "        #torch.nn.init.normal_(self.fc2.weight, mean=0, std=1.0)\n",
    "        self.fc5 = nn.Linear(10, 1).type(dtype)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        return F.relu(self.fc5(x))\n",
    "\n",
    "model = StockModel(input_size)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data, model, loss_fn):\n",
    "    losses = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in data:\n",
    "            y = y.squeeze().type(dtype)\n",
    "            x = x.squeeze().type(dtype)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            losses.append(loss.item())\n",
    "            predictions.extend(pred.tolist())\n",
    "        avg_loss = sum(losses)/len(losses)    \n",
    "    \n",
    "    return avg_loss, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data_loader, dev_data_loader, loss_fn, optimizer, epochrange, batchsize):\n",
    "    for epoch in range(epochrange):\n",
    "        losses = []\n",
    "        n_correct = 0\n",
    "        for x, y in train_data_loader:\n",
    "            y = y.squeeze().type(dtype)\n",
    "            x = x.squeeze().type(dtype)\n",
    "            \n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()    \n",
    "\n",
    "        # Compute accuracy and loss in the entire training set\n",
    "        train_avg_loss = sum(losses)/len(losses)    \n",
    "        \n",
    "        dev_avg_loss,_ = evaluate_model(dev_data_loader, model, loss_fn)\n",
    "        \n",
    "        # Display metrics\n",
    "        display_str = 'Epoch {} '\n",
    "        display_str += '\\tLoss: {:.3f} '\n",
    "        display_str += '\\tLoss (val): {:.3f}'\n",
    "        print(display_str.format(epoch, train_avg_loss, dev_avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "dev_data_loader = DataLoader(dev_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([512])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/oscar/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([255])) that is different to the input size (torch.Size([255, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \tLoss: 9.701 \tLoss (val): 0.078\n",
      "Epoch 1 \tLoss: 0.144 \tLoss (val): 0.108\n",
      "Epoch 2 \tLoss: 0.140 \tLoss (val): 0.068\n",
      "Epoch 3 \tLoss: 0.133 \tLoss (val): 0.182\n",
      "Epoch 4 \tLoss: 0.129 \tLoss (val): 0.183\n",
      "Epoch 5 \tLoss: 0.130 \tLoss (val): 0.149\n",
      "Epoch 6 \tLoss: 0.127 \tLoss (val): 0.173\n",
      "Epoch 7 \tLoss: 0.124 \tLoss (val): 0.211\n",
      "Epoch 8 \tLoss: 0.121 \tLoss (val): 0.240\n",
      "Epoch 9 \tLoss: 0.117 \tLoss (val): 0.267\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "train_model(model, train_data_loader, dev_data_loader, loss_fn, optimizer, nbr_epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "_, preds = evaluate_model(test_data, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145.04129028320312\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_data_borpi = list(zip(*test_data))\n",
    "print(preds[0])\n",
    "items_plot = [y_data_borpi[1][t] for t in range(len(y_data_borpi[1]))]\n",
    "plt.plot(list(range(len(preds))), preds)\n",
    "plt.plot(list(range(len(items_plot))), items_plot)\n",
    "axes = plt.gca()\n",
    "#axes.set_ylim([145,170])\n",
    "#axes.set_xlim([125000,129000])\n",
    "#axes.set_xlim([176950,177500])\n",
    "#axes.set_xlim([23800,24100])\n",
    "axes.set_xlim([400000,410000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
