{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params\n",
    "input_size=500\n",
    "batch_size=256\n",
    "nbr_epochs=10\n",
    "data_split_ratio=0.8\n",
    "chunksize = 100000\n",
    "lr = 0.001\n",
    "y_column = \"300s\"\n",
    "files_x = [\"data/x_Swedbank_A_500_p.csv\",]\n",
    "files_y = [\"data/y_Swedbank_A_500.csv\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(xs, ys, trainRatio):\n",
    "    t = round(len(xs)*trainRatio)\n",
    "    \n",
    "    train_data_x = torch.tensor(xs[:t].values, dtype=torch.float32)\n",
    "    train_data_y = torch.tensor(ys[:t].values, dtype=torch.float32)\n",
    "    \n",
    "    dev_data_x = torch.tensor(xs[t:].values, dtype=torch.float32)\n",
    "    dev_data_y = torch.tensor(ys[t:].values, dtype=torch.float32)\n",
    "    \n",
    "    return TensorDataset(train_data_x, train_data_y), TensorDataset(dev_data_x, dev_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute_unit = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device('cuda:0')\n",
    "#device = torch.device(\"cpu\")\n",
    "#compute_unit = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtype = torch.FloatTensor\n",
    "dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1000).type(dtype)\n",
    "        self.fc2 = nn.Linear(1000, 2000).type(dtype)\n",
    "        self.fc3 = nn.Linear(2000, 1000).type(dtype)\n",
    "        self.fc4 = nn.Linear(1000, 500).type(dtype)\n",
    "        self.fc5 = nn.Linear(500, 100).type(dtype)\n",
    "        self.fc6 = nn.Linear(100, 20).type(dtype)\n",
    "        self.fc7 = nn.Linear(20, 1).type(dtype)\n",
    "        \n",
    "        self.drop_layer = nn.Dropout(p=0.010)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print(x)\n",
    "        fc1 = self.fc1(x)\n",
    "        x = F.relu(fc1)\n",
    "        x = self.drop_layer(x)\n",
    "        #print(fc1)\n",
    "        #print(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.drop_layer(x)\n",
    "        #print(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.drop_layer(x)\n",
    "        #x = self.drop_layer(x)\n",
    "        #print(x)\n",
    "        x= F.relu(self.fc4(x))\n",
    "        #print(y)\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.drop_layer(x)\n",
    "        x = F.relu(self.fc6(x))\n",
    "        y = F.relu(self.fc7(x))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data, model, loss_fn):\n",
    "    losses = []\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in data:\n",
    "            y = y.type(dtype)\n",
    "            x = x.type(dtype)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            losses.append(loss.item())\n",
    "            predictions.extend(pred.tolist())\n",
    "        avg_loss = sum(losses)/len(losses)    \n",
    "    \n",
    "    return avg_loss, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data_loader, dev_data_loader, loss_fn, optimizer, epochrange, batchsize):\n",
    "    for epoch in range(epochrange):\n",
    "        losses = []\n",
    "        n_correct = 0\n",
    "        model.train()\n",
    "        for x, y in train_data_loader:\n",
    "            y = y.type(dtype)\n",
    "            x = x.type(dtype)\n",
    "            \n",
    "            pred = model(x)\n",
    "\n",
    "            loss = loss_fn(pred, y)\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()    \n",
    "\n",
    "        # Compute accuracy and loss in the entire training set\n",
    "        train_avg_loss = sum(losses)/len(losses)    \n",
    "        \n",
    "        dev_avg_loss,_ = evaluate_model(dev_data_loader, model, loss_fn)\n",
    "        \n",
    "        # Display metrics\n",
    "        display_str = 'Epoch {} '\n",
    "        display_str += '\\tLoss: {:.3f} '\n",
    "        display_str += '\\tLoss (val): {:.3f}'\n",
    "        print(display_str.format(epoch, train_avg_loss, dev_avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_chunk(model, loss_fn, optimizer, nbr_epochs, x_data, y_data, data_split_ratio, batch_size):\n",
    "    train_data, dev_data = splitData(x_data, y_data, data_split_ratio)\n",
    "    train_data_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    dev_data_loader = DataLoader(dev_data, batch_size=batch_size)\n",
    "    train_model(model, train_data_loader, dev_data_loader, loss_fn, optimizer, nbr_epochs, batch_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current file: data/x_Swedbank_A_500_p.csv\n",
      "Number of chunks: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/anaconda3/envs/gtx/lib/python3.7/site-packages/ipykernel_launcher.py:16: ParserWarning: Both a converter and dtype were specified for column ts - only the converter will be used\n",
      "  app.launch_new_instance()\n",
      "/home/oscar/anaconda3/envs/gtx/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/anaconda3/envs/gtx/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/oscar/anaconda3/envs/gtx/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \tLoss: 1564.465 \tLoss (val): 0.742\n",
      "Epoch 1 \tLoss: 11.635 \tLoss (val): 2.995\n",
      "Epoch 2 \tLoss: 8.632 \tLoss (val): 7.396\n",
      "Epoch 3 \tLoss: 8.153 \tLoss (val): 1.399\n",
      "Epoch 4 \tLoss: 9.003 \tLoss (val): 16.688\n",
      "Epoch 5 \tLoss: 17.618 \tLoss (val): 1.296\n",
      "Epoch 6 \tLoss: 14.399 \tLoss (val): 5.124\n",
      "Epoch 7 \tLoss: 15.729 \tLoss (val): 0.356\n",
      "Epoch 8 \tLoss: 14.063 \tLoss (val): 8.289\n",
      "Epoch 9 \tLoss: 14.565 \tLoss (val): 7.577\n",
      "Progress: 3.23%\n",
      "Epoch 0 \tLoss: 13.337 \tLoss (val): 8.315\n",
      "Epoch 1 \tLoss: 10.927 \tLoss (val): 6.921\n",
      "Epoch 2 \tLoss: 12.900 \tLoss (val): 6.684\n",
      "Epoch 3 \tLoss: 8.425 \tLoss (val): 6.383\n",
      "Epoch 4 \tLoss: 8.447 \tLoss (val): 4.103\n",
      "Epoch 5 \tLoss: 10.046 \tLoss (val): 2.527\n",
      "Epoch 6 \tLoss: 7.977 \tLoss (val): 1.352\n",
      "Epoch 7 \tLoss: 14.092 \tLoss (val): 69.923\n",
      "Epoch 8 \tLoss: 182.552 \tLoss (val): 14.661\n",
      "Epoch 9 \tLoss: 6.372 \tLoss (val): 12.462\n",
      "Progress: 6.45%\n",
      "Epoch 0 \tLoss: 5.512 \tLoss (val): 8.387\n",
      "Epoch 1 \tLoss: 5.215 \tLoss (val): 6.647\n",
      "Epoch 2 \tLoss: 4.471 \tLoss (val): 9.060\n",
      "Epoch 3 \tLoss: 4.091 \tLoss (val): 4.598\n",
      "Epoch 4 \tLoss: 4.155 \tLoss (val): 5.171\n",
      "Epoch 5 \tLoss: 4.375 \tLoss (val): 8.523\n",
      "Epoch 6 \tLoss: 4.082 \tLoss (val): 9.858\n",
      "Epoch 7 \tLoss: 4.932 \tLoss (val): 12.056\n",
      "Epoch 8 \tLoss: 5.661 \tLoss (val): 6.560\n",
      "Epoch 9 \tLoss: 7.853 \tLoss (val): 8.354\n",
      "Progress: 9.68%\n",
      "Epoch 0 \tLoss: 4.013 \tLoss (val): 5.781\n",
      "Epoch 1 \tLoss: 5.359 \tLoss (val): 3.909\n",
      "Epoch 2 \tLoss: 4.987 \tLoss (val): 4.982\n",
      "Epoch 3 \tLoss: 8.832 \tLoss (val): 4.485\n",
      "Epoch 4 \tLoss: 3.803 \tLoss (val): 4.636\n",
      "Epoch 5 \tLoss: 4.289 \tLoss (val): 1.992\n",
      "Epoch 6 \tLoss: 4.757 \tLoss (val): 0.210\n",
      "Epoch 7 \tLoss: 4.509 \tLoss (val): 0.068\n",
      "Epoch 8 \tLoss: 3.997 \tLoss (val): 10.183\n",
      "Epoch 9 \tLoss: 6.544 \tLoss (val): 2.011\n",
      "Progress: 12.90%\n",
      "Epoch 0 \tLoss: 3.039 \tLoss (val): 6.746\n"
     ]
    }
   ],
   "source": [
    "#Start training\n",
    "model = StockModel(input_size)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "model = model.to(device)\n",
    "test_data_x = pd.DataFrame()\n",
    "test_data_y = pd.DataFrame()\n",
    "for i in range(len(files_x)):\n",
    "    print(\"Current file: \" + files_x[i])\n",
    "    total_rows = sum(1 for row in open(files_x[i], 'r'))\n",
    "    number_of_loops = int(total_rows/chunksize)\n",
    "    print(\"Number of chunks: \" + str(number_of_loops))\n",
    "    current_loop = 0\n",
    "    with pd.read_csv(files_x[i], sep=\";\", dtype=\"float32\", usecols = [j for j in range(input_size)], chunksize=chunksize) as reader_x,\\\n",
    "    pd.read_csv(files_y[i], sep=\";\", dtype=\"float32\", converters = {'ts': int}, chunksize=chunksize) as reader_y:\n",
    "        for chunk_x, chunk_y in zip(reader_x, reader_y):\n",
    "            print(\"Progress: \" + \"{:.2f}\".format(100 * current_loop/number_of_loops) + \"%\")\n",
    "            x_data = chunk_x\n",
    "            y_data = chunk_y\n",
    "            if(current_loop < data_split_ratio * number_of_loops):\n",
    "                y_data = y_data[y_column]\n",
    "                train_chunk(model, loss_fn, optimizer, nbr_epochs, x_data, y_data, data_split_ratio, batch_size)\n",
    "            else:\n",
    "                print(\"Append test data\")\n",
    "                test_data_x = test_data_x.append(x_data)\n",
    "                test_data_y = test_data_y.append(y_data)\n",
    "            current_loop+=1\n",
    "\n",
    "test_data_x = torch.tensor(test_data_x.values, dtype=torch.float32)\n",
    "test_data_y = torch.tensor(test_data_y[y_column].values, dtype=torch.float32)\n",
    "test_data = TensorDataset(test_data_x, test_data_y)\n",
    "#test_data_y = test_data_y[y_column]\n",
    "#test_data = list(zip(test_data_x, test_data_y))\n",
    "#for i in range(len(files_x)):\n",
    "#    x_data = pd.read_csv(files_x[i], sep=\";\", dtype=\"float32\", usecols = [j for j in range(input_size)])\n",
    "#    y_data = pd.read_csv(files_y[i], sep=\";\", dtype=\"float32\", converters = {'ts': int})\n",
    "#    y_data = y_data[y_column]\n",
    "#    print(x_data.shape)\n",
    "#    print(y_data.shape)\n",
    "#    x_data.head()\n",
    "#    y_data.head()\n",
    "#    print(files_x[i])\n",
    "#    train_data, dev_data, test_data = splitData(x_data, y_data, data_split_ratio)\n",
    "#    train_data_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "#    dev_data_loader = DataLoader(dev_data, batch_size=batch_size)\n",
    "#    model = model.to(device)\n",
    "#    train_model(model, train_data_loader, dev_data_loader, loss_fn, optimizer, nbr_epochs, batch_size)\n",
    "#    del [[x_data, y_data, train_data, dev_data, train_data_loader, dev_data_loader]]\n",
    "#    gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/anaconda3/envs/gtx/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "_, preds = evaluate_model(test_data, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "items_plot = test_data_y2\n",
    "plt.plot(list(range(len(preds))), preds)\n",
    "plt.plot(list(range(len(items_plot))), items_plot)\n",
    "axes = plt.gca()\n",
    "#axes.set_ylim([145,170])\n",
    "#axes.set_xlim([260000,261200])\n",
    "#axes.set_xlim([100000,120000])\n",
    "axes.set_xlim([140000,160000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
