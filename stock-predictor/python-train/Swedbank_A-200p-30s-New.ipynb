{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import math\n",
    "from sklearn.metrics import r2_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params\n",
    "input_size=200\n",
    "batch_size=512\n",
    "nbr_epochs=20\n",
    "data_split_ratio=0.8\n",
    "chunksize = 1000000\n",
    "lr = 0.0001\n",
    "y_column = \"30s\"\n",
    "files_x = [\"../python-docker/Swedbank_A/x_Swedbank_A_200_p.csv\",]\n",
    "files_y = [\"../python-docker/Swedbank_A/y_Swedbank_A_200_tmp.csv\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(xs, ys, trainRatio):\n",
    "    t = round(len(xs)*trainRatio)\n",
    "    \n",
    "    train_data_x = torch.tensor(xs[:t].values, dtype=torch.float32)\n",
    "    train_data_y = torch.tensor(ys[:t].values, dtype=torch.float32)\n",
    "    \n",
    "    dev_data_x = torch.tensor(xs[t:].values, dtype=torch.float32)\n",
    "    dev_data_y = torch.tensor(ys[t:].values, dtype=torch.float32)\n",
    "    \n",
    "    return TensorDataset(train_data_x, train_data_y), TensorDataset(dev_data_x, dev_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute_unit = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device('cuda:0')\n",
    "#device = torch.device(\"cpu\")\n",
    "#compute_unit = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtype = torch.FloatTensor\n",
    "dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 300).type(dtype),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(300, 20).type(dtype),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(20, 1).type(dtype),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(self.net[0].weight)\n",
    "        torch.nn.init.xavier_uniform_(self.net[2].weight)\n",
    "        torch.nn.init.xavier_uniform_(self.net[4].weight)\n",
    "        \n",
    "        #self.fc1 = nn.Linear(input_size, 300).type(dtype)\n",
    "        #self.fc1.weight.data.uniform_(-0.1, 0.1)\n",
    "        #self.fc2 = nn.Linear(300, 20).type(dtype)\n",
    "        #self.fc2.weight.data.uniform_(-0.1, 0.1)\n",
    "        #self.fc3 = nn.Linear(20, 1).type(dtype)\n",
    "        #self.fc3.weight.data.uniform_(-0.1, 0.1)\n",
    "        #self.fc4 = nn.Linear(1, 20).type(dtype)\n",
    "        #self.fc4.weight.data.uniform_(-0.1, 0.1)\n",
    "        #self.fc5 = nn.Linear(20, 1).type(dtype)\n",
    "        #elf.fc5.weight.data.uniform_(-0.1, 0.1)\n",
    "        #self.fc6 = nn.Linear(100, 20).type(dtype)\n",
    "        #self.fc6.weight.data.uniform_(-0.1, 0.1)\n",
    "        #self.fc7 = nn.Linear(20, 1).type(dtype)\n",
    "        #self.fc7.weight.data.uniform_(-0.1, 0.1)\n",
    "        \n",
    "        #self.bn1 = nn.BatchNorm1d(num_features=input_size, track_running_stats=True)\n",
    "        #self.sig = nn.Sigmoid()\n",
    "        \n",
    "        #self.drop_layer = nn.Dropout(p=0.010)\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data, model, loss_fn):\n",
    "    losses = []\n",
    "    ys = []\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in data:\n",
    "            y = y.type(dtype)\n",
    "            x = x.type(dtype)\n",
    "            pred = model(x).squeeze()\n",
    "            loss = loss_fn(pred, y)\n",
    "            losses.append(loss.item())\n",
    "            ys.extend(y.tolist())\n",
    "            predictions.extend(pred.tolist())\n",
    "        avg_loss = sum(losses)/len(losses)    \n",
    "        \n",
    "    r2 = r2_score(ys, predictions)\n",
    "    return avg_loss, predictions, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data_loader, dev_data_loader, loss_fn, optimizer, epochrange, batchsize):\n",
    "    for epoch in range(epochrange):\n",
    "        losses = []\n",
    "        n_correct = 0\n",
    "        model.train()\n",
    "        for x, y in train_data_loader:\n",
    "            y = y.type(dtype)\n",
    "            x = x.type(dtype)\n",
    "            pred = model(x).squeeze()\n",
    "            loss = loss_fn(pred, y)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()    \n",
    "\n",
    "        # Compute accuracy and loss in the entire training set\n",
    "        train_avg_loss = sum(losses)/len(losses)    \n",
    "        \n",
    "        dev_avg_loss,_,r2 = evaluate_model(dev_data_loader, model, loss_fn)\n",
    "        \n",
    "        # Display metrics\n",
    "        display_str = 'Epoch {} '\n",
    "        display_str += '\\tLoss: {:.6f} '\n",
    "        display_str += '\\tLoss (val): {:.6f}'\n",
    "        display_str += '\\tR^2 score: {:.4f}'\n",
    "        print(display_str.format(epoch, train_avg_loss, dev_avg_loss, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_chunk(model, loss_fn, optimizer, nbr_epochs, x_data, y_data, data_split_ratio, batch_size):\n",
    "    train_data, dev_data = splitData(x_data, y_data, data_split_ratio)\n",
    "    train_data_loader = DataLoader(train_data, batch_size=batch_size, drop_last=True)\n",
    "    dev_data_loader = DataLoader(dev_data, batch_size=batch_size, drop_last=True)\n",
    "    train_model(model, train_data_loader, dev_data_loader, loss_fn, optimizer, nbr_epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current file: ../python-docker/Swedbank_A/x_Swedbank_A_200_p.csv\n",
      "Number of chunks: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kajen\\.conda\\envs\\titantesttest\\lib\\site-packages\\ipykernel_launcher.py:16: ParserWarning: Both a converter and dtype were specified for column ts - only the converter will be used\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0.00%\n",
      "Epoch 0 \tLoss: 69.295307 \tLoss (val): 0.065076\tR^2 score: 0.9375\n",
      "Epoch 1 \tLoss: 0.399226 \tLoss (val): 1.087863\tR^2 score: -0.0456\n",
      "Epoch 2 \tLoss: 0.674165 \tLoss (val): 0.364510\tR^2 score: 0.6497\n",
      "Epoch 3 \tLoss: 0.882123 \tLoss (val): 0.146160\tR^2 score: 0.8595\n",
      "Epoch 4 \tLoss: 0.973030 \tLoss (val): 0.124758\tR^2 score: 0.8801\n",
      "Epoch 5 \tLoss: 0.966249 \tLoss (val): 0.169450\tR^2 score: 0.8371\n",
      "Epoch 6 \tLoss: 0.951875 \tLoss (val): 0.266490\tR^2 score: 0.7439\n",
      "Epoch 7 \tLoss: 0.932138 \tLoss (val): 0.390163\tR^2 score: 0.6250\n",
      "Epoch 8 \tLoss: 0.911748 \tLoss (val): 0.524433\tR^2 score: 0.4960\n",
      "Epoch 9 \tLoss: 0.893053 \tLoss (val): 0.709130\tR^2 score: 0.3184\n",
      "Epoch 10 \tLoss: 0.870688 \tLoss (val): 0.861051\tR^2 score: 0.1724\n",
      "Epoch 11 \tLoss: 0.848649 \tLoss (val): 0.999828\tR^2 score: 0.0390\n",
      "Epoch 12 \tLoss: 0.827177 \tLoss (val): 1.062042\tR^2 score: -0.0207\n",
      "Epoch 13 \tLoss: 0.808323 \tLoss (val): 0.973482\tR^2 score: 0.0644\n",
      "Epoch 14 \tLoss: 0.790097 \tLoss (val): 0.752422\tR^2 score: 0.2768\n",
      "Epoch 15 \tLoss: 0.772429 \tLoss (val): 0.533555\tR^2 score: 0.4872\n",
      "Epoch 16 \tLoss: 0.756757 \tLoss (val): 0.367887\tR^2 score: 0.6464\n",
      "Epoch 17 \tLoss: 0.743051 \tLoss (val): 0.229760\tR^2 score: 0.7792\n",
      "Epoch 18 \tLoss: 0.732471 \tLoss (val): 0.100467\tR^2 score: 0.9034\n",
      "Epoch 19 \tLoss: 0.723350 \tLoss (val): 0.040888\tR^2 score: 0.9607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kajen\\.conda\\envs\\titantesttest\\lib\\site-packages\\ipykernel_launcher.py:16: ParserWarning: Both a converter and dtype were specified for column ts - only the converter will be used\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 25.00%\n",
      "Epoch 0 \tLoss: 0.679074 \tLoss (val): 0.488552\tR^2 score: 0.4946\n",
      "Epoch 1 \tLoss: 0.627874 \tLoss (val): 0.501737\tR^2 score: 0.4810\n",
      "Epoch 2 \tLoss: 0.610543 \tLoss (val): 0.503239\tR^2 score: 0.4794\n",
      "Epoch 3 \tLoss: 0.594560 \tLoss (val): 0.495292\tR^2 score: 0.4876\n",
      "Epoch 4 \tLoss: 0.578827 \tLoss (val): 0.476173\tR^2 score: 0.5074\n",
      "Epoch 5 \tLoss: 0.571962 \tLoss (val): 0.226938\tR^2 score: 0.7652\n",
      "Epoch 6 \tLoss: 0.529304 \tLoss (val): 0.243966\tR^2 score: 0.7476\n",
      "Epoch 7 \tLoss: 0.508670 \tLoss (val): 0.252647\tR^2 score: 0.7386\n",
      "Epoch 8 \tLoss: 0.506095 \tLoss (val): 0.189357\tR^2 score: 0.8041\n",
      "Epoch 9 \tLoss: 0.510699 \tLoss (val): 0.065778\tR^2 score: 0.9320\n",
      "Epoch 10 \tLoss: 0.504896 \tLoss (val): 0.029971\tR^2 score: 0.9690\n",
      "Epoch 11 \tLoss: 0.500020 \tLoss (val): 0.032689\tR^2 score: 0.9662\n",
      "Epoch 12 \tLoss: 0.487612 \tLoss (val): 0.052024\tR^2 score: 0.9462\n",
      "Epoch 13 \tLoss: 0.475381 \tLoss (val): 0.077426\tR^2 score: 0.9199\n",
      "Epoch 14 \tLoss: 0.463658 \tLoss (val): 0.119151\tR^2 score: 0.8767\n"
     ]
    }
   ],
   "source": [
    "#Start training\n",
    "model = StockModel(input_size)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, eps=0.001)\n",
    "model = model.to(device)\n",
    "test_data_x = pd.DataFrame()\n",
    "test_data_y = pd.DataFrame()\n",
    "for i in range(len(files_x)):\n",
    "    print(\"Current file: \" + files_x[i])\n",
    "    total_rows = sum(1 for row in open(files_x[i], 'r'))\n",
    "    number_of_loops = int(total_rows/chunksize)\n",
    "    print(\"Number of chunks: \" + str(number_of_loops))\n",
    "    current_loop = 0\n",
    "    with pd.read_csv(files_x[i], sep=\";\", dtype=\"float32\", usecols = [j for j in range(input_size)], chunksize=chunksize) as reader_x,\\\n",
    "    pd.read_csv(files_y[i], sep=\";\", dtype=\"float32\", converters = {'ts': int}, chunksize=chunksize) as reader_y:\n",
    "        for chunk_x, chunk_y in zip(reader_x, reader_y):\n",
    "            print(\"Progress: \" + \"{:.2f}\".format(100 * current_loop/number_of_loops) + \"%\")\n",
    "            x_data = chunk_x\n",
    "            y_data = chunk_y\n",
    "            if(current_loop < data_split_ratio * number_of_loops):\n",
    "                y_data = y_data[y_column]\n",
    "                train_chunk(model, loss_fn, optimizer, nbr_epochs, x_data, y_data, data_split_ratio, batch_size)\n",
    "            else:\n",
    "                print(\"Append test data\")\n",
    "                test_data_x = test_data_x.append(x_data)\n",
    "                test_data_y = test_data_y.append(y_data)\n",
    "            current_loop+=1\n",
    "\n",
    "test_data_x = torch.tensor(test_data_x.values, dtype=torch.float32)\n",
    "test_data_y= torch.tensor(test_data_y[y_column].values, dtype=torch.float32)\n",
    "test_data = TensorDataset(test_data_x, test_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = DataLoader(test_data, batch_size=2)\n",
    "loss, preds, r2 = evaluate_model(test_data_loader, model, loss_fn)\n",
    "print(\"Test loss: \" + str(loss))\n",
    "print(\"Test R^2: \" + str(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(preds))), preds, label=\"Predictions\")\n",
    "plt.plot(list(range(len(test_data_y))), test_data_y.tolist(), label=\"Target\")\n",
    "axes = plt.gca()\n",
    "#axes.set_ylim([146,148])\n",
    "plt.legend()\n",
    "#axes.set_xlim([260000,261200])\n",
    "#axes.set_xlim([100000,120000])\n",
    "#axes.set_xlim([140000,160000])\n",
    "#xes.set_xlim([540000,560000])\n",
    "#axes.set_xlim([610000,660000])\n",
    "#axes.set_xlim([660000,660100])\n",
    "#axes.set_ylim([157,158])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
