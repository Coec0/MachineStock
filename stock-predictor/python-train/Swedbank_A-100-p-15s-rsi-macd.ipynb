{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_ = pd.read_csv(\"../python-docker/Swedbank_A/x_Swedbank_A_100_p.csv\", sep=\";\", usecols = [i for i in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsi = pd.read_csv(\"../python-docker/Swedbank_A/x_Swedbank_A_rsi.csv\", sep=\";\", usecols=[\"Swedbank_Arsi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "macd = pd.read_csv(\"../python-docker/Swedbank_A/x_Swedbank_A_macd.csv\", sep=\";\", usecols=[\"Swedbank_Amacd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = pd.read_csv(\"../python-docker/Swedbank_A/y_Swedbank_A_100.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>15s</th>\n",
       "      <th>15ud</th>\n",
       "      <th>30s</th>\n",
       "      <th>30ud</th>\n",
       "      <th>60s</th>\n",
       "      <th>60ud</th>\n",
       "      <th>300s</th>\n",
       "      <th>300ud</th>\n",
       "      <th>600s</th>\n",
       "      <th>600ud</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>144.46</td>\n",
       "      <td>0</td>\n",
       "      <td>144.32</td>\n",
       "      <td>0</td>\n",
       "      <td>144.20</td>\n",
       "      <td>0</td>\n",
       "      <td>144.10</td>\n",
       "      <td>0</td>\n",
       "      <td>144.32</td>\n",
       "      <td>0</td>\n",
       "      <td>1598425200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144.46</td>\n",
       "      <td>0</td>\n",
       "      <td>144.32</td>\n",
       "      <td>0</td>\n",
       "      <td>144.20</td>\n",
       "      <td>0</td>\n",
       "      <td>144.22</td>\n",
       "      <td>0</td>\n",
       "      <td>144.32</td>\n",
       "      <td>0</td>\n",
       "      <td>1598425201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144.46</td>\n",
       "      <td>0</td>\n",
       "      <td>144.32</td>\n",
       "      <td>0</td>\n",
       "      <td>144.20</td>\n",
       "      <td>0</td>\n",
       "      <td>144.26</td>\n",
       "      <td>0</td>\n",
       "      <td>144.32</td>\n",
       "      <td>0</td>\n",
       "      <td>1598425202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144.46</td>\n",
       "      <td>0</td>\n",
       "      <td>144.32</td>\n",
       "      <td>0</td>\n",
       "      <td>144.12</td>\n",
       "      <td>0</td>\n",
       "      <td>144.26</td>\n",
       "      <td>0</td>\n",
       "      <td>144.32</td>\n",
       "      <td>0</td>\n",
       "      <td>1598425203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144.46</td>\n",
       "      <td>0</td>\n",
       "      <td>144.32</td>\n",
       "      <td>0</td>\n",
       "      <td>144.12</td>\n",
       "      <td>0</td>\n",
       "      <td>144.26</td>\n",
       "      <td>0</td>\n",
       "      <td>144.32</td>\n",
       "      <td>0</td>\n",
       "      <td>1598425204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      15s  15ud     30s  30ud     60s  60ud    300s  300ud    600s  600ud  \\\n",
       "0  144.46     0  144.32     0  144.20     0  144.10      0  144.32      0   \n",
       "1  144.46     0  144.32     0  144.20     0  144.22      0  144.32      0   \n",
       "2  144.46     0  144.32     0  144.20     0  144.26      0  144.32      0   \n",
       "3  144.46     0  144.32     0  144.12     0  144.26      0  144.32      0   \n",
       "4  144.46     0  144.32     0  144.12     0  144.26      0  144.32      0   \n",
       "\n",
       "           ts  \n",
       "0  1598425200  \n",
       "1  1598425201  \n",
       "2  1598425202  \n",
       "3  1598425203  \n",
       "4  1598425204  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3242927, 100)\n",
      "(3242927, 102)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Swedbank_A-price-0</th>\n",
       "      <th>Swedbank_A-price-1</th>\n",
       "      <th>Swedbank_A-price-2</th>\n",
       "      <th>Swedbank_A-price-3</th>\n",
       "      <th>Swedbank_A-price-4</th>\n",
       "      <th>Swedbank_A-price-5</th>\n",
       "      <th>Swedbank_A-price-6</th>\n",
       "      <th>Swedbank_A-price-7</th>\n",
       "      <th>Swedbank_A-price-8</th>\n",
       "      <th>Swedbank_A-price-9</th>\n",
       "      <th>...</th>\n",
       "      <th>Swedbank_A-price-92</th>\n",
       "      <th>Swedbank_A-price-93</th>\n",
       "      <th>Swedbank_A-price-94</th>\n",
       "      <th>Swedbank_A-price-95</th>\n",
       "      <th>Swedbank_A-price-96</th>\n",
       "      <th>Swedbank_A-price-97</th>\n",
       "      <th>Swedbank_A-price-98</th>\n",
       "      <th>Swedbank_A-price-99</th>\n",
       "      <th>Swedbank_Arsi</th>\n",
       "      <th>Swedbank_Amacd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>...</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>37.2882</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>...</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>37.2882</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>...</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>37.2882</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>...</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>37.2882</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>...</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>144.5</td>\n",
       "      <td>37.2882</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Swedbank_A-price-0  Swedbank_A-price-1  Swedbank_A-price-2  \\\n",
       "0               144.5               144.5               144.5   \n",
       "1               144.5               144.5               144.5   \n",
       "2               144.5               144.5               144.5   \n",
       "3               144.5               144.5               144.5   \n",
       "4               144.5               144.5               144.5   \n",
       "\n",
       "   Swedbank_A-price-3  Swedbank_A-price-4  Swedbank_A-price-5  \\\n",
       "0               144.5               144.5               144.5   \n",
       "1               144.5               144.5               144.5   \n",
       "2               144.5               144.5               144.5   \n",
       "3               144.5               144.5               144.5   \n",
       "4               144.5               144.5               144.5   \n",
       "\n",
       "   Swedbank_A-price-6  Swedbank_A-price-7  Swedbank_A-price-8  \\\n",
       "0               144.5               144.5               144.5   \n",
       "1               144.5               144.5               144.5   \n",
       "2               144.5               144.5               144.5   \n",
       "3               144.5               144.5               144.5   \n",
       "4               144.5               144.5               144.5   \n",
       "\n",
       "   Swedbank_A-price-9  ...  Swedbank_A-price-92  Swedbank_A-price-93  \\\n",
       "0               144.5  ...                144.5                144.5   \n",
       "1               144.5  ...                144.5                144.5   \n",
       "2               144.5  ...                144.5                144.5   \n",
       "3               144.5  ...                144.5                144.5   \n",
       "4               144.5  ...                144.5                144.5   \n",
       "\n",
       "   Swedbank_A-price-94  Swedbank_A-price-95  Swedbank_A-price-96  \\\n",
       "0                144.5                144.5                144.5   \n",
       "1                144.5                144.5                144.5   \n",
       "2                144.5                144.5                144.5   \n",
       "3                144.5                144.5                144.5   \n",
       "4                144.5                144.5                144.5   \n",
       "\n",
       "   Swedbank_A-price-97  Swedbank_A-price-98  Swedbank_A-price-99  \\\n",
       "0                144.5                144.5                144.5   \n",
       "1                144.5                144.5                144.5   \n",
       "2                144.5                144.5                144.5   \n",
       "3                144.5                144.5                144.5   \n",
       "4                144.5                144.5                144.5   \n",
       "\n",
       "   Swedbank_Arsi  Swedbank_Amacd  \n",
       "0        37.2882             0.0  \n",
       "1        37.2882             0.0  \n",
       "2        37.2882             0.0  \n",
       "3        37.2882             0.0  \n",
       "4        37.2882             0.0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_data_.shape)\n",
    "x_data__ = x_data_.join(rsi)\n",
    "x_data = x_data__.join(macd)\n",
    "print(x_data.shape)\n",
    "x_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'15s'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-b802c8751471>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"15s\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\titantesttest\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 851\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\titantesttest\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 959\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    960\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\titantesttest\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    352\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '15s'"
     ]
    }
   ],
   "source": [
    "y_data = y_data[\"15s\"]\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(xs, ys, trainRatio):\n",
    "    t = round(len(xs)*trainRatio)\n",
    "    \n",
    "    train_data_x = torch.tensor(xs[:t].values, dtype=torch.float32)\n",
    "    train_data_y = torch.tensor(ys[:t].values, dtype=torch.float32)\n",
    "    \n",
    "    d = round(len(xs[t:])/2)\n",
    "    \n",
    "    dev_data_x = torch.tensor(xs[t:][:d].values, dtype=torch.float32)\n",
    "    dev_data_y = torch.tensor(ys[t:][:d].values, dtype=torch.float32)\n",
    "    \n",
    "    test_data_x = torch.tensor(xs[t:][d:].values, dtype=torch.float32)\n",
    "    test_data_y = torch.tensor(ys[t:][d:].values, dtype=torch.float32)\n",
    "    \n",
    "    #print(test_data_y.shape)\n",
    "    \n",
    "    return TensorDataset(train_data_x, train_data_y), TensorDataset(dev_data_x, dev_data_y), list(zip(test_data_x, test_data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, dev_data, test_data = splitData(x_data, y_data, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=102\n",
    "batch_size=256\n",
    "nbr_epochs=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute_unit = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device('cuda:0')\n",
    "#device = torch.device(\"cpu\")\n",
    "#compute_unit = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtype = torch.FloatTensor\n",
    "dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 150).type(dtype)\n",
    "        nn.init.normal_(self.fc1.weight, mean=0, std=1)\n",
    "        self.fc1.weight = nn.Parameter(self.fc1.weight * math.sqrt(2/input_size))\n",
    "        self.fc2 = nn.Linear(150, 100).type(dtype)\n",
    "        nn.init.normal_(self.fc2.weight, mean=0, std=1)\n",
    "        self.fc2.weight = nn.Parameter(self.fc2.weight * math.sqrt(2/input_size))\n",
    "        self.fc3 = nn.Linear(100, 30).type(dtype)\n",
    "        nn.init.normal_(self.fc3.weight, mean=0, std=1)\n",
    "        self.fc3.weight = nn.Parameter(self.fc3.weight * math.sqrt(2/input_size))\n",
    "        self.fc4 = nn.Linear(30, 10).type(dtype)\n",
    "        nn.init.normal_(self.fc4.weight, mean=0, std=1)\n",
    "        self.fc4.weight = nn.Parameter(self.fc4.weight * math.sqrt(2/input_size))\n",
    "        self.fc5 = nn.Linear(10, 1).type(dtype)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        return F.relu(self.fc5(x))\n",
    "    \n",
    "model = StockModel(input_size)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data, model, loss_fn):\n",
    "    losses = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in data:\n",
    "            y = y.squeeze().type(dtype)\n",
    "            x = x.squeeze().type(dtype)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            losses.append(loss.item())\n",
    "            predictions.extend(pred.tolist())\n",
    "        avg_loss = sum(losses)/len(losses)    \n",
    "    \n",
    "    return avg_loss, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data_loader, dev_data_loader, loss_fn, optimizer, epochrange, batchsize):\n",
    "    for epoch in range(epochrange):\n",
    "        losses = []\n",
    "        n_correct = 0\n",
    "        for x, y in train_data_loader:\n",
    "            y = y.type(dtype)\n",
    "            x = x.type(dtype)\n",
    "            pred = model(x)\n",
    "            \n",
    "            loss = loss_fn(pred, y)\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()    \n",
    "\n",
    "        # Compute accuracy and loss in the entire training set\n",
    "        train_avg_loss = sum(losses)/len(losses)    \n",
    "        \n",
    "        dev_avg_loss,_ = evaluate_model(dev_data_loader, model, loss_fn)\n",
    "        \n",
    "        # Display metrics\n",
    "        display_str = 'Epoch {} '\n",
    "        display_str += '\\tLoss: {:.3f} '\n",
    "        display_str += '\\tLoss (val): {:.3f}'\n",
    "        print(display_str.format(epoch, train_avg_loss, dev_avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "dev_data_loader = DataLoader(dev_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kajen\\.conda\\envs\\titantesttest\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\kajen\\.conda\\envs\\titantesttest\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([38])) that is different to the input size (torch.Size([38, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\kajen\\.conda\\envs\\titantesttest\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([196])) that is different to the input size (torch.Size([196, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \tLoss: 6.750 \tLoss (val): 0.044\n",
      "Epoch 1 \tLoss: 0.117 \tLoss (val): 0.125\n",
      "Epoch 2 \tLoss: 0.108 \tLoss (val): 0.194\n",
      "Epoch 3 \tLoss: 0.179 \tLoss (val): 0.127\n",
      "Epoch 4 \tLoss: 0.163 \tLoss (val): 0.158\n",
      "Epoch 5 \tLoss: 0.131 \tLoss (val): 0.037\n",
      "Epoch 6 \tLoss: 0.106 \tLoss (val): 0.090\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "train_model(model, train_data_loader, dev_data_loader, loss_fn, optimizer, nbr_epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kajen\\.conda\\envs\\titantesttest\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "_, preds = evaluate_model(test_data, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153.37960815429688\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_data_borpi = list(zip(*test_data))\n",
    "print(preds[0])\n",
    "items_plot = [y_data_borpi[1][t] for t in range(len(y_data_borpi[1]))]\n",
    "plt.plot(list(range(len(preds))), preds)\n",
    "plt.plot(list(range(len(items_plot))), items_plot)\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([145,170])\n",
    "axes.set_xlim([231000,232000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
