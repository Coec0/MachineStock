{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params\n",
    "batch_size=256\n",
    "nbr_epochs=5\n",
    "data_split_ratio=0.8\n",
    "y_column = \"600s\"\n",
    "file_price_x = \"data/x_Swedbank_A_1_p.csv\"\n",
    "#files_other_x = [\"data/x_Swedbank_A_0_p_macd.csv\",\"data/x_Swedbank_A_0_p_rsi.csv\"]\n",
    "file_y = \"data/y_Swedbank_A_1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = pd.read_csv(file_price_x , sep=\";\", converters = {'ts': int})\n",
    "#for f in files_other_x:\n",
    "#    x_data = x_data.merge(pd.read_csv(f , sep=\";\", dtype=\"float32\", converters = {'ts': int}), on=\"ts\", how='inner')\n",
    "y_data_ = pd.read_csv(file_y , sep=\";\", converters = {'ts': int})\n",
    "y_data = y_data_[y_column]\n",
    "del x_data[\"ts\"]\n",
    "input_size=x_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Swedbank_A-price-0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145.139999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145.199997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145.199997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145.199997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>145.199997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Swedbank_A-price-0\n",
       "0          145.139999\n",
       "1          145.199997\n",
       "2          145.199997\n",
       "3          145.199997\n",
       "4          145.199997"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>15s</th>\n",
       "      <th>30s</th>\n",
       "      <th>60s</th>\n",
       "      <th>300s</th>\n",
       "      <th>600s</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145.0</td>\n",
       "      <td>145.00</td>\n",
       "      <td>145.26</td>\n",
       "      <td>145.38</td>\n",
       "      <td>145.26</td>\n",
       "      <td>1604390404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145.0</td>\n",
       "      <td>145.14</td>\n",
       "      <td>145.26</td>\n",
       "      <td>145.38</td>\n",
       "      <td>145.26</td>\n",
       "      <td>1604390405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145.0</td>\n",
       "      <td>145.14</td>\n",
       "      <td>145.26</td>\n",
       "      <td>145.38</td>\n",
       "      <td>145.26</td>\n",
       "      <td>1604390406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145.0</td>\n",
       "      <td>145.00</td>\n",
       "      <td>145.26</td>\n",
       "      <td>145.10</td>\n",
       "      <td>145.26</td>\n",
       "      <td>1604390407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>145.0</td>\n",
       "      <td>145.00</td>\n",
       "      <td>145.26</td>\n",
       "      <td>145.10</td>\n",
       "      <td>145.26</td>\n",
       "      <td>1604390408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     15s     30s     60s    300s    600s          ts\n",
       "0  145.0  145.00  145.26  145.38  145.26  1604390404\n",
       "1  145.0  145.14  145.26  145.38  145.26  1604390405\n",
       "2  145.0  145.14  145.26  145.38  145.26  1604390406\n",
       "3  145.0  145.00  145.26  145.10  145.26  1604390407\n",
       "4  145.0  145.00  145.26  145.10  145.26  1604390408"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    145.26\n",
       "1    145.26\n",
       "2    145.26\n",
       "3    145.26\n",
       "4    145.26\n",
       "Name: 600s, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1809210, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1809210,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(xs, ys, trainRatio):\n",
    "    t = round(len(xs)*trainRatio)\n",
    "    \n",
    "    train_data_x = torch.tensor(xs[:t].values, dtype=torch.float32)\n",
    "    train_data_y = torch.tensor(ys[:t].values, dtype=torch.float32)\n",
    "    \n",
    "    d = round(len(xs[t:])/2)\n",
    "    \n",
    "    dev_data_x = torch.tensor(xs[t:][:d].values, dtype=torch.float32)\n",
    "    dev_data_y = torch.tensor(ys[t:][:d].values, dtype=torch.float32)\n",
    "    \n",
    "    test_data_x = torch.tensor(xs[t:][d:].values, dtype=torch.float32)\n",
    "    test_data_y = torch.tensor(ys[t:][d:].values, dtype=torch.float32)\n",
    "    \n",
    "    #print(test_data_y.shape)\n",
    "    \n",
    "    return TensorDataset(train_data_x, train_data_y), TensorDataset(dev_data_x, dev_data_y), list(zip(test_data_x, test_data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute_unit = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device('cuda:0')\n",
    "#device = torch.device(\"cpu\")\n",
    "#compute_unit = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtype = torch.FloatTensor\n",
    "dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 100).type(dtype)\n",
    "        self.fc2 = nn.Linear(100, 40).type(dtype)\n",
    "        self.fc3 = nn.Linear(40, 1).type(dtype)\n",
    "        \n",
    "        self.drop_layer = nn.Dropout(p=0.010)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print(x)\n",
    "        fc1 = self.fc1(x)\n",
    "        x = F.relu(fc1)\n",
    "        x = self.drop_layer(x)\n",
    "        #print(fc1)\n",
    "        #print(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #print(x)\n",
    "        y = F.relu(self.fc3(x))\n",
    "        return y\n",
    "\n",
    "model = StockModel(input_size)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data, model, loss_fn):\n",
    "    losses = []\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in data:\n",
    "            y = y.squeeze().type(dtype)\n",
    "            x = x.squeeze().type(dtype)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            losses.append(loss.item())\n",
    "            predictions.extend(pred.tolist())\n",
    "        avg_loss = sum(losses)/len(losses)  \n",
    "    \n",
    "    return avg_loss, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data_loader, dev_data_loader, loss_fn, optimizer, epochrange, batchsize):\n",
    "    for epoch in range(epochrange):\n",
    "        losses = []\n",
    "        n_correct = 0\n",
    "        model.train()\n",
    "        for x, y in train_data_loader:\n",
    "            y = y.type(dtype)\n",
    "            x = x.type(dtype)\n",
    "            \n",
    "            pred = model(x)\n",
    "\n",
    "            loss = loss_fn(pred, y)\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()    \n",
    "\n",
    "        # Compute accuracy and loss in the entire training set\n",
    "        train_avg_loss = sum(losses)/len(losses)    \n",
    "        \n",
    "        dev_avg_loss,_ = evaluate_model(dev_data_loader, model, loss_fn)\n",
    "        \n",
    "        # Display metrics\n",
    "        display_str = 'Epoch {} '\n",
    "        display_str += '\\tLoss: {:.3f} '\n",
    "        display_str += '\\tLoss (val): {:.3f}'\n",
    "        print(display_str.format(epoch, train_avg_loss, dev_avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/oscar/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([199])) that is different to the input size (torch.Size([199, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/oscar/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([185])) that is different to the input size (torch.Size([185, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \tLoss: 287.595 \tLoss (val): 0.520\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a72910e3878c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdev_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbr_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-cf2016cf1c2f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_data_loader, dev_data_loader, loss_fn, optimizer, epochrange, batchsize)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Start training\n",
    "train_data, dev_data, test_data = splitData(x_data, y_data, data_split_ratio)\n",
    "train_data_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "dev_data_loader = DataLoader(dev_data, batch_size=batch_size)\n",
    "model = model.to(device)\n",
    "train_model(model, train_data_loader, dev_data_loader, loss_fn, optimizer, nbr_epochs, batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, preds = evaluate_model(test_data, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_borpi = list(y_data)\n",
    "x_data_borpi = list(x_data[\"Swedbank_A-price-0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148.1199951171875\n",
      "146.82000732421875\n"
     ]
    }
   ],
   "source": [
    "print(x_data_borpi[120350])\n",
    "print(y_data_borpi[119750]) #120350\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(list(range(len(y_data_borpi))), y_data_borpi)\n",
    "plt.plot(list(range(len(x_data_borpi)-600)), x_data_borpi[600:])\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([120,170])\n",
    "#axes.set_xlim([250000,265000])\n",
    "axes.set_xlim([119000,121000])\n",
    "#axes.set_xlim([142500,145000])\n",
    "plt.show()\n",
    "#axes = plt.gca()\n",
    "#axes.set_ylim([120,170])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
