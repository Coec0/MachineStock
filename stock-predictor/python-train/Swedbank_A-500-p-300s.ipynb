{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params\n",
    "input_size=500\n",
    "batch_size=512\n",
    "nbr_epochs=10\n",
    "data_split_ratio=0.8\n",
    "chunksize = 100000\n",
    "lr = 0.0001\n",
    "y_column = \"300s\"\n",
    "files_x = [\"data/x_Swedbank_A_500_p.csv\",]\n",
    "files_y = [\"data/y_Swedbank_A_500.csv\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(xs, ys, trainRatio):\n",
    "    t = round(len(xs)*trainRatio)\n",
    "    \n",
    "    train_data_x = torch.tensor(xs[:t].values, dtype=torch.float32)\n",
    "    train_data_y = torch.tensor(ys[:t].values, dtype=torch.float32)\n",
    "    \n",
    "    dev_data_x = torch.tensor(xs[t:].values, dtype=torch.float32)\n",
    "    dev_data_y = torch.tensor(ys[t:].values, dtype=torch.float32)\n",
    "    \n",
    "    return TensorDataset(train_data_x, train_data_y), TensorDataset(dev_data_x, dev_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute_unit = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device('cuda:0')\n",
    "#device = torch.device(\"cpu\")\n",
    "#compute_unit = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtype = torch.FloatTensor\n",
    "dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1000).type(dtype)\n",
    "        self.fc2 = nn.Linear(1000, 2000).type(dtype)\n",
    "        self.fc3 = nn.Linear(2000, 1000).type(dtype)\n",
    "        self.fc4 = nn.Linear(1000, 500).type(dtype)\n",
    "        self.fc5 = nn.Linear(500, 100).type(dtype)\n",
    "        self.fc6 = nn.Linear(100, 20).type(dtype)\n",
    "        self.fc7 = nn.Linear(20, 1).type(dtype)\n",
    "        \n",
    "        self.drop_layer = nn.Dropout(p=0.010)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print(x)\n",
    "        fc1 = self.fc1(x)\n",
    "        x = F.relu(fc1)\n",
    "        #x = self.drop_layer(x)\n",
    "        #print(fc1)\n",
    "        #print(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #x = self.drop_layer(x)\n",
    "        #print(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        #x = self.drop_layer(x)\n",
    "        #x = self.drop_layer(x)\n",
    "        #print(x)\n",
    "        x= F.relu(self.fc4(x))\n",
    "        #print(y)\n",
    "        x = F.relu(self.fc5(x))\n",
    "        #x = self.drop_layer(x)\n",
    "        x = F.relu(self.fc6(x))\n",
    "        y = F.relu(self.fc7(x))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data, model, loss_fn):\n",
    "    losses = []\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in data:\n",
    "            y = y.type(dtype)\n",
    "            x = x.type(dtype)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            losses.append(loss.item())\n",
    "            predictions.extend(pred.tolist())\n",
    "        avg_loss = sum(losses)/len(losses)    \n",
    "    \n",
    "    return avg_loss, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data_loader, dev_data_loader, loss_fn, optimizer, epochrange, batchsize):\n",
    "    for epoch in range(epochrange):\n",
    "        losses = []\n",
    "        n_correct = 0\n",
    "        model.train()\n",
    "        for x, y in train_data_loader:\n",
    "            y = y.type(dtype)\n",
    "            x = x.type(dtype)\n",
    "            \n",
    "            pred = model(x)\n",
    "\n",
    "            loss = loss_fn(pred, y)\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()    \n",
    "\n",
    "        # Compute accuracy and loss in the entire training set\n",
    "        train_avg_loss = sum(losses)/len(losses)    \n",
    "        \n",
    "        dev_avg_loss,_ = evaluate_model(dev_data_loader, model, loss_fn)\n",
    "        \n",
    "        # Display metrics\n",
    "        display_str = 'Epoch {} '\n",
    "        display_str += '\\tLoss: {:.3f} '\n",
    "        display_str += '\\tLoss (val): {:.3f}'\n",
    "        print(display_str.format(epoch, train_avg_loss, dev_avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_chunk(model, loss_fn, optimizer, nbr_epochs, x_data, y_data, data_split_ratio, batch_size):\n",
    "    train_data, dev_data = splitData(x_data, y_data, data_split_ratio)\n",
    "    train_data_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    dev_data_loader = DataLoader(dev_data, batch_size=batch_size)\n",
    "    train_model(model, train_data_loader, dev_data_loader, loss_fn, optimizer, nbr_epochs, batch_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current file: data/x_Swedbank_A_500_p.csv\n",
      "Number of chunks: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/anaconda3/envs/gtx/lib/python3.7/site-packages/ipykernel_launcher.py:16: ParserWarning: Both a converter and dtype were specified for column ts - only the converter will be used\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/anaconda3/envs/gtx/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([512])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/oscar/anaconda3/envs/gtx/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/oscar/anaconda3/envs/gtx/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \tLoss: 1476.229 \tLoss (val): 0.239\n",
      "Epoch 1 \tLoss: 0.307 \tLoss (val): 0.394\n",
      "Epoch 2 \tLoss: 0.335 \tLoss (val): 0.590\n",
      "Epoch 3 \tLoss: 0.278 \tLoss (val): 0.367\n",
      "Epoch 4 \tLoss: 0.330 \tLoss (val): 0.889\n",
      "Epoch 5 \tLoss: 0.456 \tLoss (val): 1.061\n",
      "Epoch 6 \tLoss: 0.470 \tLoss (val): 0.406\n",
      "Epoch 7 \tLoss: 0.486 \tLoss (val): 1.695\n",
      "Epoch 8 \tLoss: 0.503 \tLoss (val): 3.641\n",
      "Epoch 9 \tLoss: 0.429 \tLoss (val): 2.894\n",
      "Progress: 3.23%\n",
      "Epoch 0 \tLoss: 0.443 \tLoss (val): 0.123\n",
      "Epoch 1 \tLoss: 0.342 \tLoss (val): 0.121\n",
      "Epoch 2 \tLoss: 0.401 \tLoss (val): 0.175\n",
      "Epoch 3 \tLoss: 0.470 \tLoss (val): 0.161\n",
      "Epoch 4 \tLoss: 0.466 \tLoss (val): 0.315\n",
      "Epoch 5 \tLoss: 0.440 \tLoss (val): 1.044\n",
      "Epoch 6 \tLoss: 0.536 \tLoss (val): 1.528\n",
      "Epoch 7 \tLoss: 0.723 \tLoss (val): 1.702\n",
      "Epoch 8 \tLoss: 0.671 \tLoss (val): 1.074\n",
      "Epoch 9 \tLoss: 0.599 \tLoss (val): 0.206\n",
      "Progress: 6.45%\n",
      "Epoch 0 \tLoss: 0.435 \tLoss (val): 0.392\n",
      "Epoch 1 \tLoss: 0.412 \tLoss (val): 1.113\n",
      "Epoch 2 \tLoss: 0.521 \tLoss (val): 0.600\n",
      "Epoch 3 \tLoss: 0.613 \tLoss (val): 0.811\n",
      "Epoch 4 \tLoss: 0.658 \tLoss (val): 0.821\n",
      "Epoch 5 \tLoss: 0.735 \tLoss (val): 0.690\n",
      "Epoch 6 \tLoss: 0.890 \tLoss (val): 0.696\n",
      "Epoch 7 \tLoss: 0.932 \tLoss (val): 0.625\n",
      "Epoch 8 \tLoss: 0.825 \tLoss (val): 0.442\n",
      "Epoch 9 \tLoss: 0.714 \tLoss (val): 0.369\n",
      "Progress: 9.68%\n",
      "Epoch 0 \tLoss: 0.624 \tLoss (val): 0.113\n",
      "Epoch 1 \tLoss: 0.531 \tLoss (val): 0.154\n",
      "Epoch 2 \tLoss: 0.525 \tLoss (val): 0.298\n",
      "Epoch 3 \tLoss: 0.636 \tLoss (val): 0.513\n",
      "Epoch 4 \tLoss: 0.681 \tLoss (val): 0.739\n",
      "Epoch 5 \tLoss: 0.687 \tLoss (val): 0.812\n",
      "Epoch 6 \tLoss: 0.686 \tLoss (val): 0.883\n",
      "Epoch 7 \tLoss: 0.680 \tLoss (val): 0.928\n",
      "Epoch 8 \tLoss: 0.685 \tLoss (val): 0.954\n",
      "Epoch 9 \tLoss: 0.690 \tLoss (val): 1.046\n",
      "Progress: 12.90%\n",
      "Epoch 0 \tLoss: 1.364 \tLoss (val): 0.390\n",
      "Epoch 1 \tLoss: 1.048 \tLoss (val): 0.130\n",
      "Epoch 2 \tLoss: 0.952 \tLoss (val): 0.069\n",
      "Epoch 3 \tLoss: 0.929 \tLoss (val): 0.037\n",
      "Epoch 4 \tLoss: 0.935 \tLoss (val): 0.035\n",
      "Epoch 5 \tLoss: 0.949 \tLoss (val): 0.052\n",
      "Epoch 6 \tLoss: 0.948 \tLoss (val): 0.096\n",
      "Epoch 7 \tLoss: 0.928 \tLoss (val): 0.122\n",
      "Epoch 8 \tLoss: 0.896 \tLoss (val): 0.130\n",
      "Epoch 9 \tLoss: 0.876 \tLoss (val): 0.127\n",
      "Progress: 16.13%\n",
      "Epoch 0 \tLoss: 2.096 \tLoss (val): 0.134\n",
      "Epoch 1 \tLoss: 1.804 \tLoss (val): 0.826\n",
      "Epoch 2 \tLoss: 1.624 \tLoss (val): 1.064\n",
      "Epoch 3 \tLoss: 1.437 \tLoss (val): 0.755\n",
      "Epoch 4 \tLoss: 1.353 \tLoss (val): 0.561\n",
      "Epoch 5 \tLoss: 1.309 \tLoss (val): 0.464\n",
      "Epoch 6 \tLoss: 1.293 \tLoss (val): 0.404\n",
      "Epoch 7 \tLoss: 1.274 \tLoss (val): 0.360\n",
      "Epoch 8 \tLoss: 1.266 \tLoss (val): 0.331\n",
      "Epoch 9 \tLoss: 1.256 \tLoss (val): 0.298\n",
      "Progress: 19.35%\n",
      "Epoch 0 \tLoss: 0.516 \tLoss (val): 1.766\n",
      "Epoch 1 \tLoss: 0.665 \tLoss (val): 2.601\n",
      "Epoch 2 \tLoss: 0.733 \tLoss (val): 3.043\n",
      "Epoch 3 \tLoss: 0.739 \tLoss (val): 3.216\n",
      "Epoch 4 \tLoss: 0.727 \tLoss (val): 2.804\n",
      "Epoch 5 \tLoss: 0.702 \tLoss (val): 1.851\n",
      "Epoch 6 \tLoss: 0.634 \tLoss (val): 0.879\n",
      "Epoch 7 \tLoss: 0.563 \tLoss (val): 0.494\n",
      "Epoch 8 \tLoss: 0.536 \tLoss (val): 0.626\n",
      "Epoch 9 \tLoss: 0.531 \tLoss (val): 0.709\n",
      "Progress: 22.58%\n",
      "Epoch 0 \tLoss: 0.709 \tLoss (val): 0.336\n",
      "Epoch 1 \tLoss: 0.611 \tLoss (val): 0.206\n",
      "Epoch 2 \tLoss: 0.620 \tLoss (val): 0.140\n",
      "Epoch 3 \tLoss: 0.621 \tLoss (val): 0.112\n",
      "Epoch 4 \tLoss: 0.609 \tLoss (val): 0.094\n",
      "Epoch 5 \tLoss: 0.621 \tLoss (val): 0.094\n",
      "Epoch 6 \tLoss: 0.621 \tLoss (val): 0.095\n",
      "Epoch 7 \tLoss: 0.618 \tLoss (val): 0.103\n",
      "Epoch 8 \tLoss: 0.632 \tLoss (val): 0.141\n",
      "Epoch 9 \tLoss: 0.609 \tLoss (val): 0.114\n",
      "Progress: 25.81%\n",
      "Epoch 0 \tLoss: 0.330 \tLoss (val): 0.426\n",
      "Epoch 1 \tLoss: 0.463 \tLoss (val): 0.155\n",
      "Epoch 2 \tLoss: 0.420 \tLoss (val): 0.040\n",
      "Epoch 3 \tLoss: 0.330 \tLoss (val): 0.146\n",
      "Epoch 4 \tLoss: 0.259 \tLoss (val): 0.275\n",
      "Epoch 5 \tLoss: 0.324 \tLoss (val): 0.553\n",
      "Epoch 6 \tLoss: 0.375 \tLoss (val): 1.000\n",
      "Epoch 7 \tLoss: 0.393 \tLoss (val): 1.288\n",
      "Epoch 8 \tLoss: 0.399 \tLoss (val): 1.459\n",
      "Epoch 9 \tLoss: 0.403 \tLoss (val): 1.571\n",
      "Progress: 29.03%\n",
      "Epoch 0 \tLoss: 0.505 \tLoss (val): 4.087\n",
      "Epoch 1 \tLoss: 0.467 \tLoss (val): 3.799\n",
      "Epoch 2 \tLoss: 0.425 \tLoss (val): 3.729\n",
      "Epoch 3 \tLoss: 0.421 \tLoss (val): 3.704\n",
      "Epoch 4 \tLoss: 0.425 \tLoss (val): 3.929\n",
      "Epoch 5 \tLoss: 0.416 \tLoss (val): 3.569\n",
      "Epoch 6 \tLoss: 0.433 \tLoss (val): 3.611\n",
      "Epoch 7 \tLoss: 0.409 \tLoss (val): 3.550\n",
      "Epoch 8 \tLoss: 0.405 \tLoss (val): 3.577\n",
      "Epoch 9 \tLoss: 0.406 \tLoss (val): 3.531\n",
      "Progress: 32.26%\n",
      "Epoch 0 \tLoss: 0.578 \tLoss (val): 0.303\n",
      "Epoch 1 \tLoss: 0.524 \tLoss (val): 0.288\n",
      "Epoch 2 \tLoss: 0.468 \tLoss (val): 0.277\n",
      "Epoch 3 \tLoss: 0.452 \tLoss (val): 0.276\n",
      "Epoch 4 \tLoss: 0.448 \tLoss (val): 0.277\n",
      "Epoch 5 \tLoss: 0.443 \tLoss (val): 0.277\n",
      "Epoch 6 \tLoss: 0.437 \tLoss (val): 0.271\n",
      "Epoch 7 \tLoss: 0.473 \tLoss (val): 0.276\n",
      "Epoch 8 \tLoss: 0.441 \tLoss (val): 0.279\n",
      "Epoch 9 \tLoss: 0.437 \tLoss (val): 0.280\n",
      "Progress: 35.48%\n",
      "Epoch 0 \tLoss: 1.613 \tLoss (val): 1.222\n",
      "Epoch 1 \tLoss: 0.846 \tLoss (val): 0.426\n",
      "Epoch 2 \tLoss: 0.743 \tLoss (val): 0.099\n",
      "Epoch 3 \tLoss: 0.725 \tLoss (val): 0.098\n",
      "Epoch 4 \tLoss: 0.767 \tLoss (val): 0.245\n",
      "Epoch 5 \tLoss: 0.871 \tLoss (val): 0.870\n",
      "Epoch 6 \tLoss: 1.068 \tLoss (val): 0.935\n",
      "Epoch 7 \tLoss: 1.501 \tLoss (val): 0.241\n",
      "Epoch 8 \tLoss: 1.641 \tLoss (val): 2.705\n",
      "Epoch 9 \tLoss: 1.391 \tLoss (val): 2.784\n",
      "Progress: 38.71%\n",
      "Epoch 0 \tLoss: 0.908 \tLoss (val): 0.658\n",
      "Epoch 1 \tLoss: 0.650 \tLoss (val): 0.795\n",
      "Epoch 2 \tLoss: 0.841 \tLoss (val): 0.849\n",
      "Epoch 3 \tLoss: 0.814 \tLoss (val): 0.824\n",
      "Epoch 4 \tLoss: 0.849 \tLoss (val): 0.802\n",
      "Epoch 5 \tLoss: 0.867 \tLoss (val): 0.792\n",
      "Epoch 6 \tLoss: 0.893 \tLoss (val): 0.809\n",
      "Epoch 7 \tLoss: 0.875 \tLoss (val): 0.807\n",
      "Epoch 8 \tLoss: 0.865 \tLoss (val): 0.806\n",
      "Epoch 9 \tLoss: 0.861 \tLoss (val): 0.772\n",
      "Progress: 41.94%\n",
      "Epoch 0 \tLoss: 1.486 \tLoss (val): 3.264\n",
      "Epoch 1 \tLoss: 1.681 \tLoss (val): 8.009\n",
      "Epoch 2 \tLoss: 1.813 \tLoss (val): 11.164\n",
      "Epoch 3 \tLoss: 1.721 \tLoss (val): 11.193\n",
      "Epoch 4 \tLoss: 1.502 \tLoss (val): 11.589\n",
      "Epoch 5 \tLoss: 1.440 \tLoss (val): 12.244\n",
      "Epoch 6 \tLoss: 1.409 \tLoss (val): 12.000\n",
      "Epoch 7 \tLoss: 1.411 \tLoss (val): 12.473\n",
      "Epoch 8 \tLoss: 1.391 \tLoss (val): 12.748\n",
      "Epoch 9 \tLoss: 1.388 \tLoss (val): 12.703\n",
      "Progress: 45.16%\n",
      "Epoch 0 \tLoss: 1.121 \tLoss (val): 1.185\n",
      "Epoch 1 \tLoss: 0.846 \tLoss (val): 2.005\n",
      "Epoch 2 \tLoss: 0.847 \tLoss (val): 1.410\n",
      "Epoch 3 \tLoss: 0.859 \tLoss (val): 0.990\n",
      "Epoch 4 \tLoss: 0.854 \tLoss (val): 0.622\n",
      "Epoch 5 \tLoss: 0.840 \tLoss (val): 0.353\n",
      "Epoch 6 \tLoss: 0.834 \tLoss (val): 0.241\n",
      "Epoch 7 \tLoss: 0.831 \tLoss (val): 0.227\n",
      "Epoch 8 \tLoss: 0.828 \tLoss (val): 0.310\n",
      "Epoch 9 \tLoss: 0.827 \tLoss (val): 0.462\n",
      "Progress: 48.39%\n",
      "Epoch 0 \tLoss: 0.713 \tLoss (val): 0.195\n",
      "Epoch 1 \tLoss: 0.751 \tLoss (val): 0.194\n",
      "Epoch 2 \tLoss: 0.749 \tLoss (val): 0.201\n",
      "Epoch 3 \tLoss: 0.747 \tLoss (val): 0.217\n",
      "Epoch 4 \tLoss: 0.743 \tLoss (val): 0.235\n",
      "Epoch 5 \tLoss: 0.745 \tLoss (val): 0.251\n",
      "Epoch 6 \tLoss: 0.746 \tLoss (val): 0.268\n",
      "Epoch 7 \tLoss: 0.745 \tLoss (val): 0.270\n",
      "Epoch 8 \tLoss: 0.744 \tLoss (val): 0.284\n",
      "Epoch 9 \tLoss: 0.744 \tLoss (val): 0.287\n",
      "Progress: 51.61%\n",
      "Epoch 0 \tLoss: 0.371 \tLoss (val): 0.128\n",
      "Epoch 1 \tLoss: 0.462 \tLoss (val): 0.218\n",
      "Epoch 2 \tLoss: 0.499 \tLoss (val): 0.417\n",
      "Epoch 3 \tLoss: 0.544 \tLoss (val): 0.546\n",
      "Epoch 4 \tLoss: 0.572 \tLoss (val): 0.556\n",
      "Epoch 5 \tLoss: 0.578 \tLoss (val): 0.569\n",
      "Epoch 6 \tLoss: 0.584 \tLoss (val): 0.563\n",
      "Epoch 7 \tLoss: 0.577 \tLoss (val): 0.567\n",
      "Epoch 8 \tLoss: 0.579 \tLoss (val): 0.562\n",
      "Epoch 9 \tLoss: 0.579 \tLoss (val): 0.574\n",
      "Progress: 54.84%\n",
      "Epoch 0 \tLoss: 0.546 \tLoss (val): 0.122\n",
      "Epoch 1 \tLoss: 0.430 \tLoss (val): 0.228\n",
      "Epoch 2 \tLoss: 0.483 \tLoss (val): 0.306\n",
      "Epoch 3 \tLoss: 0.506 \tLoss (val): 0.311\n",
      "Epoch 4 \tLoss: 0.515 \tLoss (val): 0.326\n",
      "Epoch 5 \tLoss: 0.511 \tLoss (val): 0.310\n",
      "Epoch 6 \tLoss: 0.516 \tLoss (val): 0.314\n",
      "Epoch 7 \tLoss: 0.507 \tLoss (val): 0.301\n",
      "Epoch 8 \tLoss: 0.506 \tLoss (val): 0.371\n",
      "Epoch 9 \tLoss: 0.521 \tLoss (val): 0.291\n",
      "Progress: 58.06%\n",
      "Epoch 0 \tLoss: 0.198 \tLoss (val): 0.156\n",
      "Epoch 1 \tLoss: 0.190 \tLoss (val): 0.152\n",
      "Epoch 2 \tLoss: 0.160 \tLoss (val): 0.256\n",
      "Epoch 3 \tLoss: 0.221 \tLoss (val): 0.367\n",
      "Epoch 4 \tLoss: 0.277 \tLoss (val): 0.691\n",
      "Epoch 5 \tLoss: 0.286 \tLoss (val): 0.828\n",
      "Epoch 6 \tLoss: 0.288 \tLoss (val): 0.769\n",
      "Epoch 7 \tLoss: 0.296 \tLoss (val): 0.770\n",
      "Epoch 8 \tLoss: 0.325 \tLoss (val): 0.771\n",
      "Epoch 9 \tLoss: 0.308 \tLoss (val): 0.837\n",
      "Progress: 61.29%\n",
      "Epoch 0 \tLoss: 0.517 \tLoss (val): 0.051\n",
      "Epoch 1 \tLoss: 0.406 \tLoss (val): 0.026\n",
      "Epoch 2 \tLoss: 0.402 \tLoss (val): 0.073\n",
      "Epoch 3 \tLoss: 0.406 \tLoss (val): 0.142\n",
      "Epoch 4 \tLoss: 0.415 \tLoss (val): 0.235\n",
      "Epoch 5 \tLoss: 0.431 \tLoss (val): 0.353\n",
      "Epoch 6 \tLoss: 0.467 \tLoss (val): 0.547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 \tLoss: 0.559 \tLoss (val): 0.580\n",
      "Epoch 8 \tLoss: 0.937 \tLoss (val): 0.137\n",
      "Epoch 9 \tLoss: 0.748 \tLoss (val): 0.091\n",
      "Progress: 64.52%\n",
      "Epoch 0 \tLoss: 0.357 \tLoss (val): 0.140\n",
      "Epoch 1 \tLoss: 0.429 \tLoss (val): 0.100\n",
      "Epoch 2 \tLoss: 0.438 \tLoss (val): 0.092\n",
      "Epoch 3 \tLoss: 0.432 \tLoss (val): 0.080\n",
      "Epoch 4 \tLoss: 0.423 \tLoss (val): 0.056\n",
      "Epoch 5 \tLoss: 0.412 \tLoss (val): 0.056\n",
      "Epoch 6 \tLoss: 0.410 \tLoss (val): 0.056\n",
      "Epoch 7 \tLoss: 0.401 \tLoss (val): 0.066\n",
      "Epoch 8 \tLoss: 0.390 \tLoss (val): 0.082\n",
      "Epoch 9 \tLoss: 0.378 \tLoss (val): 0.105\n",
      "Progress: 67.74%\n",
      "Epoch 0 \tLoss: 0.503 \tLoss (val): 0.051\n",
      "Epoch 1 \tLoss: 0.509 \tLoss (val): 0.179\n",
      "Epoch 2 \tLoss: 0.457 \tLoss (val): 0.130\n",
      "Epoch 3 \tLoss: 0.439 \tLoss (val): 0.097\n",
      "Epoch 4 \tLoss: 0.431 \tLoss (val): 0.086\n",
      "Epoch 5 \tLoss: 0.427 \tLoss (val): 0.079\n",
      "Epoch 6 \tLoss: 0.425 \tLoss (val): 0.077\n",
      "Epoch 7 \tLoss: 0.435 \tLoss (val): 0.104\n",
      "Epoch 8 \tLoss: 0.419 \tLoss (val): 0.070\n",
      "Epoch 9 \tLoss: 0.421 \tLoss (val): 0.075\n",
      "Progress: 70.97%\n",
      "Epoch 0 \tLoss: 0.261 \tLoss (val): 0.436\n",
      "Epoch 1 \tLoss: 0.332 \tLoss (val): 0.435\n",
      "Epoch 2 \tLoss: 0.371 \tLoss (val): 0.445\n",
      "Epoch 3 \tLoss: 0.385 \tLoss (val): 0.444\n",
      "Epoch 4 \tLoss: 0.389 \tLoss (val): 0.450\n",
      "Epoch 5 \tLoss: 0.388 \tLoss (val): 0.451\n",
      "Epoch 6 \tLoss: 0.388 \tLoss (val): 0.452\n",
      "Epoch 7 \tLoss: 0.384 \tLoss (val): 0.453\n",
      "Epoch 8 \tLoss: 0.387 \tLoss (val): 0.460\n",
      "Epoch 9 \tLoss: 0.383 \tLoss (val): 0.447\n",
      "Progress: 74.19%\n",
      "Epoch 0 \tLoss: 3.615 \tLoss (val): 0.261\n",
      "Epoch 1 \tLoss: 4.760 \tLoss (val): 0.264\n",
      "Epoch 2 \tLoss: 3.261 \tLoss (val): 0.066\n",
      "Epoch 3 \tLoss: 2.787 \tLoss (val): 0.056\n",
      "Epoch 4 \tLoss: 2.532 \tLoss (val): 0.140\n",
      "Epoch 5 \tLoss: 2.413 \tLoss (val): 0.256\n",
      "Epoch 6 \tLoss: 2.328 \tLoss (val): 0.319\n",
      "Epoch 7 \tLoss: 2.344 \tLoss (val): 0.389\n",
      "Epoch 8 \tLoss: 2.298 \tLoss (val): 0.399\n",
      "Epoch 9 \tLoss: 2.312 \tLoss (val): 0.409\n",
      "Progress: 77.42%\n",
      "Epoch 0 \tLoss: 0.723 \tLoss (val): 1.034\n",
      "Epoch 1 \tLoss: 0.754 \tLoss (val): 0.713\n",
      "Epoch 2 \tLoss: 0.869 \tLoss (val): 0.357\n",
      "Epoch 3 \tLoss: 0.931 \tLoss (val): 0.235\n",
      "Epoch 4 \tLoss: 0.966 \tLoss (val): 0.266\n",
      "Epoch 5 \tLoss: 1.003 \tLoss (val): 0.314\n",
      "Epoch 6 \tLoss: 1.039 \tLoss (val): 0.306\n",
      "Epoch 7 \tLoss: 1.057 \tLoss (val): 0.192\n",
      "Epoch 8 \tLoss: 1.091 \tLoss (val): 0.204\n",
      "Epoch 9 \tLoss: 1.090 \tLoss (val): 0.182\n",
      "Progress: 80.65%\n",
      "Append test data\n",
      "Progress: 83.87%\n",
      "Append test data\n",
      "Progress: 87.10%\n",
      "Append test data\n",
      "Progress: 90.32%\n",
      "Append test data\n",
      "Progress: 93.55%\n",
      "Append test data\n",
      "Progress: 96.77%\n",
      "Append test data\n",
      "Progress: 100.00%\n",
      "Append test data\n"
     ]
    }
   ],
   "source": [
    "#Start training\n",
    "model = StockModel(input_size)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "model = model.to(device)\n",
    "test_data_x = pd.DataFrame()\n",
    "test_data_y = pd.DataFrame()\n",
    "for i in range(len(files_x)):\n",
    "    print(\"Current file: \" + files_x[i])\n",
    "    total_rows = sum(1 for row in open(files_x[i], 'r'))\n",
    "    number_of_loops = int(total_rows/chunksize)\n",
    "    print(\"Number of chunks: \" + str(number_of_loops))\n",
    "    current_loop = 0\n",
    "    with pd.read_csv(files_x[i], sep=\";\", dtype=\"float32\", usecols = [j for j in range(input_size)], chunksize=chunksize) as reader_x,\\\n",
    "    pd.read_csv(files_y[i], sep=\";\", dtype=\"float32\", converters = {'ts': int}, chunksize=chunksize) as reader_y:\n",
    "        for chunk_x, chunk_y in zip(reader_x, reader_y):\n",
    "            print(\"Progress: \" + \"{:.2f}\".format(100 * current_loop/number_of_loops) + \"%\")\n",
    "            x_data = chunk_x\n",
    "            y_data = chunk_y\n",
    "            if(current_loop < data_split_ratio * number_of_loops):\n",
    "                y_data = y_data[y_column]\n",
    "                train_chunk(model, loss_fn, optimizer, nbr_epochs, x_data, y_data, data_split_ratio, batch_size)\n",
    "            else:\n",
    "                print(\"Append test data\")\n",
    "                test_data_x = test_data_x.append(x_data)\n",
    "                test_data_y = test_data_y.append(y_data)\n",
    "            current_loop+=1\n",
    "\n",
    "test_data_x = torch.tensor(test_data_x.values, dtype=torch.float32)\n",
    "test_data_y = torch.tensor(test_data_y[y_column].values, dtype=torch.float32)\n",
    "test_data = TensorDataset(test_data_x, test_data_y)\n",
    "#test_data_y = test_data_y[y_column]\n",
    "#test_data = list(zip(test_data_x, test_data_y))\n",
    "#for i in range(len(files_x)):\n",
    "#    x_data = pd.read_csv(files_x[i], sep=\";\", dtype=\"float32\", usecols = [j for j in range(input_size)])\n",
    "#    y_data = pd.read_csv(files_y[i], sep=\";\", dtype=\"float32\", converters = {'ts': int})\n",
    "#    y_data = y_data[y_column]\n",
    "#    print(x_data.shape)\n",
    "#    print(y_data.shape)\n",
    "#    x_data.head()\n",
    "#    y_data.head()\n",
    "#    print(files_x[i])\n",
    "#    train_data, dev_data, test_data = splitData(x_data, y_data, data_split_ratio)\n",
    "#    train_data_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "#    dev_data_loader = DataLoader(dev_data, batch_size=batch_size)\n",
    "#    model = model.to(device)\n",
    "#    train_model(model, train_data_loader, dev_data_loader, loss_fn, optimizer, nbr_epochs, batch_size)\n",
    "#    del [[x_data, y_data, train_data, dev_data, train_data_loader, dev_data_loader]]\n",
    "#    gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/anaconda3/envs/gtx/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "_, preds = evaluate_model(test_data, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "items_plot = test_data_y\n",
    "plt.plot(list(range(len(preds))), preds)\n",
    "plt.plot(list(range(len(items_plot))), items_plot)\n",
    "axes = plt.gca()\n",
    "#axes.set_ylim([145,170])\n",
    "#axes.set_xlim([260000,261200])\n",
    "#axes.set_xlim([100000,120000])\n",
    "#axes.set_xlim([140000,160000])\n",
    "\n",
    "#axes.set_xlim([540000,560000])\n",
    "axes.set_xlim([610000,660000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
